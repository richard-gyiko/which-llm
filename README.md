# which-llm

A command-line interface for querying AI model benchmarks from [Artificial Analysis](https://artificialanalysis.ai), enriched with capability metadata from [models.dev](https://models.dev). Helps you decide which LLM to use for your task.

## Installation

### macOS / Linux (Homebrew)

```bash
brew tap richard-gyiko/tap
brew install which-llm
```

### Windows (Scoop)

```powershell
scoop bucket add richard-gyiko https://github.com/richard-gyiko/scoop-bucket
scoop install which-llm
```

### Manual Download

Download the latest release from [GitHub Releases](https://github.com/richard-gyiko/which-llm-cli/releases):

```bash
# macOS (Apple Silicon)
curl -LO https://github.com/richard-gyiko/which-llm-cli/releases/latest/download/which-llm-aarch64-apple-darwin.tar.gz
tar -xzf which-llm-aarch64-apple-darwin.tar.gz
sudo mv which-llm /usr/local/bin/

# macOS (Intel)
curl -LO https://github.com/richard-gyiko/which-llm-cli/releases/latest/download/which-llm-x86_64-apple-darwin.tar.gz
tar -xzf which-llm-x86_64-apple-darwin.tar.gz
sudo mv which-llm /usr/local/bin/

# Linux
curl -LO https://github.com/richard-gyiko/which-llm-cli/releases/latest/download/which-llm-x86_64-unknown-linux-gnu.tar.gz
tar -xzf which-llm-x86_64-unknown-linux-gnu.tar.gz
sudo mv which-llm /usr/local/bin/
```

### From Source

```bash
cargo install --path .
```

## Setup

1. Create an account at [Artificial Analysis](https://artificialanalysis.ai/login) and generate an API key
2. Create a profile with your API key:

```bash
which-llm profile create default --api-key YOUR_API_KEY
```

Or set the `ARTIFICIAL_ANALYSIS_API_KEY` environment variable.

## Usage

### Query LLM Models

```bash
# List all LLM models (default: markdown table)
which-llm llms

# Filter by creator and sort by intelligence
which-llm llms --creator openai --sort intelligence

# Output as JSON for scripting
which-llm llms --json

# Output as CSV
which-llm llms --csv
```

### Query Media Models

```bash
# Text-to-image rankings
which-llm text-to-image

# With category breakdown
which-llm text-to-image --categories

# Other media endpoints
which-llm image-editing
which-llm text-to-speech
which-llm text-to-video
which-llm image-to-video
```

### SQL Queries

Use SQL to filter, sort, and aggregate cached data with full expressiveness:

```bash
# Best coding models under $5/M output price
which-llm query "SELECT name, creator, coding, output_price FROM llms WHERE coding > 40 AND output_price < 5 ORDER BY coding DESC"

# Fastest models with good intelligence
which-llm query "SELECT name, intelligence, tps FROM llms WHERE intelligence > 35 AND tps > 100 ORDER BY tps DESC LIMIT 10"

# Compare creators by average intelligence
which-llm query "SELECT creator, COUNT(*) as models, ROUND(AVG(intelligence), 1) as avg_intel FROM llms WHERE intelligence IS NOT NULL GROUP BY creator ORDER BY avg_intel DESC"

# Top image generation models
which-llm query "SELECT name, creator, elo, rank FROM text_to_image WHERE elo > 1200 ORDER BY elo DESC"

# Models with tool calling and large context windows
which-llm query "SELECT name, creator, context_window, tool_call FROM llms WHERE tool_call = true AND context_window > 100000 ORDER BY context_window DESC"

# Reasoning models with their capabilities
which-llm query "SELECT name, creator, intelligence, reasoning, context_window FROM llms WHERE reasoning = true ORDER BY intelligence DESC LIMIT 10"

# List available tables and their schemas
which-llm query --tables
```

#### Available Tables

| Table | Source Command |
|-------|----------------|
| `llms` | `which-llm llms` |
| `text_to_image` | `which-llm text-to-image` |
| `image_editing` | `which-llm image-editing` |
| `text_to_speech` | `which-llm text-to-speech` |
| `text_to_video` | `which-llm text-to-video` |
| `image_to_video` | `which-llm image-to-video` |

#### LLMs Table Columns

**Core Fields (from Artificial Analysis)**

| Column | Type | Description |
|--------|------|-------------|
| `id` | VARCHAR | Model ID |
| `name` | VARCHAR | Model name |
| `slug` | VARCHAR | URL slug |
| `creator` | VARCHAR | Creator name |
| `creator_slug` | VARCHAR | Creator slug |
| `release_date` | VARCHAR | Release date |
| `intelligence` | DOUBLE | Intelligence index |
| `coding` | DOUBLE | Coding index |
| `math` | DOUBLE | Math index |
| `mmlu_pro` | DOUBLE | MMLU-Pro score |
| `gpqa` | DOUBLE | GPQA score |
| `hle` | DOUBLE | HLE score |
| `livecodebench` | DOUBLE | LiveCodeBench score |
| `scicode` | DOUBLE | SciCode score |
| `math_500` | DOUBLE | MATH-500 score |
| `aime` | DOUBLE | AIME score |
| `input_price` | DOUBLE | Input price per 1M tokens |
| `output_price` | DOUBLE | Output price per 1M tokens |
| `price` | DOUBLE | Blended price (3:1 ratio) |
| `tps` | DOUBLE | Tokens per second |
| `latency` | DOUBLE | Time to first token (seconds) |

**Capability Fields (enriched from [models.dev](https://models.dev))**

| Column | Type | Description |
|--------|------|-------------|
| `reasoning` | BOOLEAN | Supports chain-of-thought reasoning |
| `tool_call` | BOOLEAN | Supports function/tool calling |
| `structured_output` | BOOLEAN | Supports structured JSON output |
| `attachment` | BOOLEAN | Supports file attachments |
| `temperature` | BOOLEAN | Supports temperature parameter |
| `context_window` | BIGINT | Maximum context window (tokens) |
| `max_input_tokens` | BIGINT | Maximum input tokens |
| `max_output_tokens` | BIGINT | Maximum output tokens |
| `input_modalities` | VARCHAR | Input types (e.g., "text,image") |
| `output_modalities` | VARCHAR | Output types (e.g., "text") |
| `knowledge_cutoff` | VARCHAR | Training data cutoff date |
| `open_weights` | BOOLEAN | Model weights are publicly available |
| `last_updated` | VARCHAR | Last update date |
| `models_dev_matched` | BOOLEAN | Whether model was matched to models.dev |

> **Note:** Capability fields are `NULL` for models not matched to models.dev (~53% of models). Use `models_dev_matched = true` to filter for models with full capability data.

#### Media Tables Columns

All media tables (`text_to_image`, `image_editing`, etc.) share this schema:

| Column | Type | Description |
|--------|------|-------------|
| `id` | VARCHAR | Model ID |
| `name` | VARCHAR | Model name |
| `slug` | VARCHAR | URL slug |
| `creator` | VARCHAR | Creator name |
| `elo` | DOUBLE | ELO score |
| `rank` | INTEGER | Rank |
| `release_date` | VARCHAR | Release date |

### Other Commands

```bash
# Manage cache
which-llm cache status
which-llm cache clear

# Manage profiles
which-llm profile list
which-llm profile create work --api-key KEY
which-llm profile default work
```

### Output Formats

- **Markdown** (default): AI-agent friendly tables
- `--json`: Full JSON response
- `--csv`: CSV format
- `--table`: ASCII table
- `--plain`: Tab-separated values

### Options

- `-p, --profile <NAME>`: Use a specific profile
- `--refresh`: Bypass cache and fetch fresh data
- `-q, --quiet`: Suppress attribution notice (for scripting)

## Agent Skill

The [`which-llm`](https://github.com/richard-gyiko/which-llm) skill helps AI coding assistants select the right model for a task, following the [Agent Skills](https://agentskills.io) open standard.

Instead of manually querying benchmarks, an agent can load this skill to:

1. **Classify your task** into a skill type (transformational, analytical, tool-using, agentic)
2. **Derive requirements** (minimum intelligence/coding scores needed)
3. **Query and recommend** models that fit your constraints (budget, speed, latency)

### Install Skill

```bash
# Install for your AI coding tool (project-level)
which-llm skill install cursor
which-llm skill install claude
which-llm skill install opencode
which-llm skill install codex
which-llm skill install windsurf
which-llm skill install copilot
which-llm skill install antigravity

# Install globally (available in all projects)
which-llm skill install cursor --global

# List supported tools and paths
which-llm skill list

# Remove installed skill
which-llm skill uninstall cursor
```

See the [which-llm repository](https://github.com/richard-gyiko/which-llm) for full skill documentation.

## Attribution

- Benchmark data provided by [Artificial Analysis](https://artificialanalysis.ai)
- Capability metadata provided by [models.dev](https://models.dev)

This CLI uses the [Artificial Analysis API](https://artificialanalysis.ai/documentation). Per the API terms, attribution is required for all use of the data.

## License

MIT
